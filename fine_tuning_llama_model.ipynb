{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 10262850,
          "sourceType": "datasetVersion",
          "datasetId": 6348843
        },
        {
          "sourceId": 10312501,
          "sourceType": "datasetVersion",
          "datasetId": 6384044
        }
      ],
      "dockerImageVersionId": 30823,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "fine tuning llama model",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gmoew/Fine-tuning-Llama-3.2.1B/blob/main/fine_tuning_llama_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "Fr6v3ppChp8q"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "thanhtran05_b1_dataset_csv_path = kagglehub.dataset_download('thanhtran05/b1-dataset-csv')\n",
        "thanhtran05_qa_cybersecurity_path = kagglehub.dataset_download('thanhtran05/qa-cybersecurity')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "-CfjnPxmhp8v"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T13:30:59.608311Z",
          "iopub.execute_input": "2024-12-28T13:30:59.608599Z",
          "iopub.status.idle": "2024-12-28T13:30:59.90925Z",
          "shell.execute_reply.started": "2024-12-28T13:30:59.608577Z",
          "shell.execute_reply": "2024-12-28T13:30:59.908412Z"
        },
        "id": "eMCg_OJshp8x",
        "outputId": "312b39e7-9edf-4173-cc8c-a78f8bc2498f"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/qa-cybersecurity/Untitled spreadsheet - Sheet1.csv\n/kaggle/input/b1-dataset-csv/processed_1.csv\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "pip install peft bitsandbytes trl datasets"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T13:31:05.211874Z",
          "iopub.execute_input": "2024-12-28T13:31:05.212335Z",
          "iopub.status.idle": "2024-12-28T13:31:24.025922Z",
          "shell.execute_reply.started": "2024-12-28T13:31:05.212307Z",
          "shell.execute_reply": "2024-12-28T13:31:24.025084Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "vEtlMx8Ghp8y",
        "outputId": "f5d57f63-2a08-44db-ad4b-59e055bf4e1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting peft\n  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\nCollecting trl\n  Downloading trl-0.13.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.4.1+cu121)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.44.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.5)\nRequirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.34.2)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.5)\nCollecting huggingface-hub>=0.25.0 (from peft)\n  Downloading huggingface_hub-0.27.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (4.12.2)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl) (13.8.1)\nCollecting transformers (from peft)\n  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (18.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.9.11)\nCollecting tokenizers<0.22,>=0.21 (from transformers->peft)\n  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.14.0-py3-none-any.whl (374 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.8/374.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading trl-0.13.0-py3-none-any.whl (293 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.4/293.4 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.27.0-py3-none-any.whl (450 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.5/450.5 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transformers-4.47.1-py3-none-any.whl (10.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: huggingface-hub, tokenizers, bitsandbytes, transformers, peft, trl\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.24.7\n    Uninstalling huggingface-hub-0.24.7:\n      Successfully uninstalled huggingface-hub-0.24.7\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.19.1\n    Uninstalling tokenizers-0.19.1:\n      Successfully uninstalled tokenizers-0.19.1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.44.2\n    Uninstalling transformers-4.44.2:\n      Successfully uninstalled transformers-4.44.2\nSuccessfully installed bitsandbytes-0.45.0 huggingface-hub-0.27.0 peft-0.14.0 tokenizers-0.21.0 transformers-4.47.1 trl-0.13.0\nNote: you may need to restart the kernel to use updated packages.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logging in Huggingface"
      ],
      "metadata": {
        "id": "gA9e8sKIhp80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login('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')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T13:31:29.328114Z",
          "iopub.execute_input": "2024-12-28T13:31:29.328416Z",
          "iopub.status.idle": "2024-12-28T13:31:29.824021Z",
          "shell.execute_reply.started": "2024-12-28T13:31:29.328384Z",
          "shell.execute_reply": "2024-12-28T13:31:29.82315Z"
        },
        "id": "ynFcAaVQhp81"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "6-7Wg8pkhp82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from datasets import Dataset, load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    HfArgumentParser,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    logging,\n",
        ")\n",
        "from peft import LoraConfig, PeftModel\n",
        "from trl import SFTTrainer\n",
        "from google.colab import files\n",
        "import pandas as pd"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T13:31:35.612811Z",
          "iopub.execute_input": "2024-12-28T13:31:35.613152Z",
          "iopub.status.idle": "2024-12-28T13:31:51.429592Z",
          "shell.execute_reply.started": "2024-12-28T13:31:35.613124Z",
          "shell.execute_reply": "2024-12-28T13:31:51.428918Z"
        },
        "id": "DlwGqLVChp84"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('/kaggle/input/qa-cybersecurity/Untitled spreadsheet - Sheet1.csv')\n",
        "\n",
        "dataset.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T13:31:55.615686Z",
          "iopub.execute_input": "2024-12-28T13:31:55.616117Z",
          "iopub.status.idle": "2024-12-28T13:31:55.681684Z",
          "shell.execute_reply.started": "2024-12-28T13:31:55.616074Z",
          "shell.execute_reply": "2024-12-28T13:31:55.681019Z"
        },
        "id": "5-pNaF6Php85",
        "outputId": "7debdc13-ee7b-4f05-846e-30c4cc6ed343"
      },
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "   index                                           Question  \\\n0      1  Which of the following would be the best examp...   \n1      2  Enacted in 2002, this U.S. law requires every ...   \n2      3  Brad has done some research and determined a c...   \n3      4  An ethical hacker is hired to test the securit...   \n4      5  When an attack by a hacker is politically moti...   \n\n                                              Answer  \n0  C. If you’re doing something as a deterrent, y...  \n1  A. FISMA has been around since 2002 and was up...  \n2  B. ALE = ARO × SLE. To determine ARO, divide t...  \n3  A. In this example, an ethical hacker was hire...  \n4  D. Hackers who use their skills and talents to...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>Question</th>\n      <th>Answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Which of the following would be the best examp...</td>\n      <td>C. If you’re doing something as a deterrent, y...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Enacted in 2002, this U.S. law requires every ...</td>\n      <td>A. FISMA has been around since 2002 and was up...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Brad has done some research and determined a c...</td>\n      <td>B. ALE = ARO × SLE. To determine ARO, divide t...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>An ethical hacker is hired to test the securit...</td>\n      <td>A. In this example, an ethical hacker was hire...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>When an attack by a hacker is politically moti...</td>\n      <td>D. Hackers who use their skills and talents to...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['text'] = '<s>[INST] ' + dataset['Question'] + '[/INST] ' + dataset['Answer'] +'</s>'\n",
        "\n",
        "dataset = Dataset.from_pandas(dataset[['text']])\n",
        "dataset"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T13:31:59.611698Z",
          "iopub.execute_input": "2024-12-28T13:31:59.612024Z",
          "iopub.status.idle": "2024-12-28T13:31:59.633586Z",
          "shell.execute_reply.started": "2024-12-28T13:31:59.611996Z",
          "shell.execute_reply": "2024-12-28T13:31:59.63269Z"
        },
        "id": "FMVbSbguhp86",
        "outputId": "ea34e906-e39b-416b-dbd0-530e7471883d"
      },
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['text'],\n    num_rows: 247\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'meta-llama/Llama-3.2-1B'\n",
        "\n",
        "lora_r = 64  # Dimension of LoRA attention\n",
        "lora_alpha = 16  # Scaling factor for LoRA\n",
        "lora_dropout = 0.1  # Dropout rate in LoRA layers\n",
        "\n",
        "#4-bit precision settings for model efficiency\n",
        "use_4bit = True  # Enable 4-bit precision\n",
        "bnb_4bit_compute_dtype = \"float16\"  # Data type for computations\n",
        "bnb_4bit_quant_type = \"nf4\"  # Quantization method\n",
        "use_nested_quant = False  # Enable double quantization for more compression\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T13:32:03.951598Z",
          "iopub.execute_input": "2024-12-28T13:32:03.951912Z",
          "iopub.status.idle": "2024-12-28T13:32:03.956048Z",
          "shell.execute_reply.started": "2024-12-28T13:32:03.951879Z",
          "shell.execute_reply": "2024-12-28T13:32:03.955146Z"
        },
        "id": "ppgNpwAshp87"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Training settings\n",
        "output_dir = \"results\"  # Where to save model and results\n",
        "num_train_epochs = 5  # Total number of training epochs\n",
        "fp16 = False  # Use mixed precision training\n",
        "bf16 = False  # Use bfloat16 precision with P100 GPUs\n",
        "per_device_train_batch_size = 4  # Training batch size per GPU\n",
        "per_device_eval_batch_size = 4  # Evaluation batch size per GPU\n",
        "gradient_accumulation_steps = 1  # Number of steps for gradient accumulation\n",
        "gradient_checkpointing = True  # Save memory during training\n",
        "max_grad_norm = 0.3  # Max norm for gradient clipping\n",
        "learning_rate = 2e-4  # Initial learning rate\n",
        "weight_decay = 0.001  # Weight decay for regularization\n",
        "optim = \"paged_adamw_32bit\"  # Optimizer choice\n",
        "lr_scheduler_type = \"cosine\"  # Learning rate scheduler\n",
        "max_steps = -1  # Set total number of training steps\n",
        "warmup_ratio = 0.03  # Warmup ratio for learning rate\n",
        "group_by_length = True  # Group sequences by length for efficiency\n",
        "save_steps = 0  # Checkpoint save frequency\n",
        "logging_steps = 10  # Logging frequency\n",
        "\n",
        "#Sequence-to-sequence (SFT) training settings\n",
        "max_seq_length = None  # Max sequence length\n",
        "packing = False  # Pack short sequences together\n",
        "device_map = {\"\": 0}  # Load model on specific GPU"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T13:32:10.871979Z",
          "iopub.execute_input": "2024-12-28T13:32:10.872281Z",
          "iopub.status.idle": "2024-12-28T13:32:10.877292Z",
          "shell.execute_reply.started": "2024-12-28T13:32:10.872259Z",
          "shell.execute_reply": "2024-12-28T13:32:10.876508Z"
        },
        "id": "0qs453wqhp87"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
        "\n",
        "#Configuring the 4-bit quantization and precision for the model\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=use_4bit,\n",
        "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
        "    bnb_4bit_compute_dtype=compute_dtype,\n",
        "    bnb_4bit_use_double_quant=use_nested_quant,\n",
        ")\n",
        "\n",
        "#Verifying if the current GPU supports bfloat16 to suggest using it for better performance\n",
        "if compute_dtype == torch.float16 and use_4bit:\n",
        "    major, _ = torch.cuda.get_device_capability()\n",
        "    if major >= 8:\n",
        "        print(\"=\" * 80)\n",
        "        print(\"Accelerate training with bf16=True\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "#Loading the specified model with the above quantization configuration\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=device_map\n",
        ")\n",
        "model.config.use_cache = False  # Disable caching to save memory\n",
        "model.config.pretraining_tp = 1"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T13:32:26.512463Z",
          "iopub.execute_input": "2024-12-28T13:32:26.512796Z",
          "iopub.status.idle": "2024-12-28T13:33:29.287641Z",
          "shell.execute_reply.started": "2024-12-28T13:32:26.512768Z",
          "shell.execute_reply": "2024-12-28T13:33:29.28699Z"
        },
        "id": "RpMmg7Lyhp88",
        "outputId": "1b03b603-8991-49c1-9daf-f462d714c052",
        "colab": {
          "referenced_widgets": [
            "e683e82530214857844f493d197c71e8",
            "bc3dc887d2a943be8d746e8fad3dc27f",
            "411cc8a8c9754a91ac1268949c5b8584"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/843 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e683e82530214857844f493d197c71e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc3dc887d2a943be8d746e8fad3dc27f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "generation_config.json:   0%|          | 0.00/185 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "411cc8a8c9754a91ac1268949c5b8584"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token  # Setting the pad token\n",
        "tokenizer.padding_side = \"right\"  # Adjusting padding to the right to avoid issues during training\n",
        "\n",
        "#Configuring LoRA parameters for the model to fine-tune its attention mechanisms\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=lora_alpha,\n",
        "    lora_dropout=lora_dropout,\n",
        "    r=lora_r,\n",
        "    bias=\"none\",  # Setting the bias option for LoRA\n",
        "    task_type=\"CAUSAL_LM\",  # Defining the task type as causal language modeling\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T13:33:40.721261Z",
          "iopub.execute_input": "2024-12-28T13:33:40.721548Z",
          "iopub.status.idle": "2024-12-28T13:33:41.292975Z",
          "shell.execute_reply.started": "2024-12-28T13:33:40.721527Z",
          "shell.execute_reply": "2024-12-28T13:33:41.292137Z"
        },
        "id": "BabevPhhhp89"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "training_arguments = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    per_device_train_batch_size=per_device_train_batch_size,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    optim=optim,\n",
        "    save_steps=save_steps,\n",
        "    logging_steps=logging_steps,\n",
        "    learning_rate=learning_rate,\n",
        "    weight_decay=weight_decay,\n",
        "    fp16=fp16,\n",
        "    bf16=bf16,\n",
        "    max_grad_norm=max_grad_norm,\n",
        "    max_steps=max_steps,\n",
        "    warmup_ratio=warmup_ratio,\n",
        "    group_by_length=group_by_length,  # Grouping by length for efficient batching\n",
        "    lr_scheduler_type=lr_scheduler_type,\n",
        "    report_to=\"tensorboard\"  # Reporting to TensorBoard for monitoring\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T13:33:46.640373Z",
          "iopub.execute_input": "2024-12-28T13:33:46.640659Z",
          "iopub.status.idle": "2024-12-28T13:33:46.668677Z",
          "shell.execute_reply.started": "2024-12-28T13:33:46.640638Z",
          "shell.execute_reply": "2024-12-28T13:33:46.667974Z"
        },
        "id": "1vFlJza0hp89"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset,\n",
        "    peft_config=peft_config,\n",
        "    processing_class=tokenizer,\n",
        "    args=training_arguments,\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T13:33:49.936544Z",
          "iopub.execute_input": "2024-12-28T13:33:49.936841Z",
          "iopub.status.idle": "2024-12-28T13:33:51.085008Z",
          "shell.execute_reply.started": "2024-12-28T13:33:49.93682Z",
          "shell.execute_reply": "2024-12-28T13:33:51.084347Z"
        },
        "id": "EkyMyEDxhp8-",
        "outputId": "bdb32f42-2a63-477e-cfd0-5023bc9b0601",
        "colab": {
          "referenced_widgets": [
            "393609146d3c4ff2904f0917627ce0de"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/247 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "393609146d3c4ff2904f0917627ce0de"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T13:33:53.978147Z",
          "iopub.execute_input": "2024-12-28T13:33:53.978439Z",
          "iopub.status.idle": "2024-12-28T13:37:38.580331Z",
          "shell.execute_reply.started": "2024-12-28T13:33:53.978416Z",
          "shell.execute_reply": "2024-12-28T13:37:38.579568Z"
        },
        "id": "TI8GgUqnhp8-",
        "outputId": "9301093f-4b91-4582-e2bc-97193b68b407"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='310' max='310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [310/310 03:41, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>2.872100</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>2.847200</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>2.486900</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>2.373900</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>2.375400</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>2.304600</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>2.190800</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>2.256700</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>2.198200</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>2.250400</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>2.166900</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>2.228000</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>2.191600</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>2.065000</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>2.180400</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>2.096700</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>2.012000</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>2.189200</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>2.208000</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>2.034100</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>2.162600</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>2.016900</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>2.002400</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>2.086200</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>2.032100</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>2.020300</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>2.045100</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>1.882300</td>\n    </tr>\n    <tr>\n      <td>290</td>\n      <td>2.114700</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>2.057300</td>\n    </tr>\n    <tr>\n      <td>310</td>\n      <td>2.077800</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "TrainOutput(global_step=310, training_loss=2.1943828029017296, metrics={'train_runtime': 224.2326, 'train_samples_per_second': 5.508, 'train_steps_per_second': 1.382, 'total_flos': 1416401588035584.0, 'train_loss': 2.1943828029017296, 'epoch': 5.0})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the finetuned model"
      ],
      "metadata": {
        "id": "1WY7o44Hhp8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the fine-tuned model\n",
        "new_model = 'Finetuned-Llama-3.2-1B-model'\n",
        "trainer.model.save_pretrained(new_model)\n",
        "trainer.model.push_to_hub(new_model, use_temp_dir=False)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T13:39:28.86897Z",
          "iopub.execute_input": "2024-12-28T13:39:28.869278Z",
          "iopub.status.idle": "2024-12-28T13:39:31.096383Z",
          "shell.execute_reply.started": "2024-12-28T13:39:28.869255Z",
          "shell.execute_reply": "2024-12-28T13:39:31.095687Z"
        },
        "id": "S5J_fr6Fhp8_",
        "outputId": "a54a1822-618a-4e17-f5b4-de72ee2f15b6",
        "colab": {
          "referenced_widgets": [
            "b6bc09605de54795ba798668eac5ebb7"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "adapter_model.safetensors:   0%|          | 0.00/27.3M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6bc09605de54795ba798668eac5ebb7"
            }
          },
          "metadata": {}
        },
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/plain": "CommitInfo(commit_url='https://huggingface.co/gmeowmeow/Finetuned-Llama-3.2-1B-model/commit/4b13f8cbcc344b47715962fc3f7668d2816d22de', commit_message='Upload model', commit_description='', oid='4b13f8cbcc344b47715962fc3f7668d2816d22de', pr_url=None, repo_url=RepoUrl('https://huggingface.co/gmeowmeow/Finetuned-Llama-3.2-1B-model', endpoint='https://huggingface.co', repo_type='model', repo_id='gmeowmeow/Finetuned-Llama-3.2-1B-model'), pr_revision=None, pr_num=None)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.push_to_hub(new_model, use_temp_dir=False)\n",
        "tokenizer.push_to_hub(new_model, use_temp_dir=False)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T13:39:50.363245Z",
          "iopub.execute_input": "2024-12-28T13:39:50.363559Z",
          "iopub.status.idle": "2024-12-28T13:39:54.708364Z",
          "shell.execute_reply.started": "2024-12-28T13:39:50.363535Z",
          "shell.execute_reply": "2024-12-28T13:39:54.707501Z"
        },
        "id": "ow22jO2thp8_",
        "outputId": "c746d99c-626f-4edc-fa7f-d551bf51fb6e",
        "colab": {
          "referenced_widgets": [
            "93e302af18314210a60f413a1313a430",
            "7ae62040918041a59c368cf561f9a619",
            "bd27c31fc39b41c0aaf831ffe00fbed3"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93e302af18314210a60f413a1313a430"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "adapter_model.safetensors:   0%|          | 0.00/27.3M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ae62040918041a59c368cf561f9a619"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd27c31fc39b41c0aaf831ffe00fbed3"
            }
          },
          "metadata": {}
        },
        {
          "execution_count": 19,
          "output_type": "execute_result",
          "data": {
            "text/plain": "CommitInfo(commit_url='https://huggingface.co/gmeowmeow/Finetuned-Llama-3.2-1B-model/commit/f8d4d88c10e8abef13a15cabb64a66dbe156f119', commit_message='Upload tokenizer', commit_description='', oid='f8d4d88c10e8abef13a15cabb64a66dbe156f119', pr_url=None, repo_url=RepoUrl('https://huggingface.co/gmeowmeow/Finetuned-Llama-3.2-1B-model', endpoint='https://huggingface.co', repo_type='model', repo_id='gmeowmeow/Finetuned-Llama-3.2-1B-model'), pr_revision=None, pr_num=None)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the model"
      ],
      "metadata": {
        "id": "sq-yNg6khp9A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Đầu vào: Bộ dữ liệu B1 được cung cấp\n",
        "Đầu ra: Câu trả lời gồm đáp án lựa chọn cùng lời giải thích\n",
        "\n",
        "Độ chính xác của mô hình được đánh giá dựa vào số câu trả lời trùng với 'ground_truth' của bộ B1"
      ],
      "metadata": {
        "id": "5lKycxfGhp9A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tải bộ dataset B1"
      ],
      "metadata": {
        "id": "vCEyfvTbhp9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logging.set_verbosity(logging.CRITICAL)\n",
        "\n",
        "test_dataset = pd.read_csv('/kaggle/input/b1-dataset-csv/processed_1.csv')\n",
        "test_dataset.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T13:40:05.338846Z",
          "iopub.execute_input": "2024-12-28T13:40:05.339188Z",
          "iopub.status.idle": "2024-12-28T13:40:05.35321Z",
          "shell.execute_reply.started": "2024-12-28T13:40:05.339161Z",
          "shell.execute_reply": "2024-12-28T13:40:05.352351Z"
        },
        "id": "NC1zpSojhp9B",
        "outputId": "fafacdf2-1ec5-4286-9354-f621f1fd412c"
      },
      "outputs": [
        {
          "execution_count": 20,
          "output_type": "execute_result",
          "data": {
            "text/plain": "   index                                           question ground_truth\n0      1  You have successfully logged on a Linux system...            A\n1      2  What is the following command used for?\\r\\nsql...            B\n2      3  Sam, a web developer, was instructed to incorp...            D\n3      4  Which of the following is assured by the use o...            D\n4      5  What is not a PCI compliance recommendation?\\r...            C",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>question</th>\n      <th>ground_truth</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>You have successfully logged on a Linux system...</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>What is the following command used for?\\r\\nsql...</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Sam, a web developer, was instructed to incorp...</td>\n      <td>D</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Which of the following is assured by the use o...</td>\n      <td>D</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>What is not a PCI compliance recommendation?\\r...</td>\n      <td>C</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sử dụng model đã được finetune"
      ],
      "metadata": {
        "id": "wzkd64oqhp9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"gmeowmeow/Finetuned-Llama-3.2-1B-model\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gmeowmeow/Finetuned-Llama-3.2-1B-model\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T13:40:29.438813Z",
          "iopub.execute_input": "2024-12-28T13:40:29.439171Z",
          "iopub.status.idle": "2024-12-28T13:40:34.778366Z",
          "shell.execute_reply.started": "2024-12-28T13:40:29.439144Z",
          "shell.execute_reply": "2024-12-28T13:40:34.777428Z"
        },
        "id": "lRBfJIB9hp9B",
        "outputId": "d83866c6-a0f8-49cb-bc6d-1f64cfdcbe8b",
        "colab": {
          "referenced_widgets": [
            "45c202712b524a64aa1be658ff512edc",
            "d96f8d476d9b42918b4cc153a9d1a4db",
            "49b2c5c241444315bb8b994d8a782c8c",
            "efacf93603cd4ff2acd2fb528b73115d",
            "a9b9dfa11f4c451aadc4a715e40923c5"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45c202712b524a64aa1be658ff512edc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d96f8d476d9b42918b4cc153a9d1a4db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/449 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49b2c5c241444315bb8b994d8a782c8c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "adapter_config.json:   0%|          | 0.00/719 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "efacf93603cd4ff2acd2fb528b73115d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "adapter_model.safetensors:   0%|          | 0.00/27.3M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9b9dfa11f4c451aadc4a715e40923c5"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming `model` and `tokenizer` are already defined\n",
        "pipe = pipeline(task='text-generation',\n",
        "                model=model,\n",
        "                tokenizer=tokenizer,\n",
        "                max_new_tokens=250)\n",
        "\n",
        "for i in range(len(test_dataset)):\n",
        "  prompt = test_dataset['question'][i]\n",
        "  result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
        "  # Creating a new column 'answer' if it doesn't exist to store the results\n",
        "  # OR Change 'answer' to 'Expected_answer' if your original data has an 'Expected_answer' column for storing the results\n",
        "  test_dataset.loc[i, 'answer'] = result[0]['generated_text'].split(\"[/INST]\")[1]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T13:40:38.202892Z",
          "iopub.execute_input": "2024-12-28T13:40:38.203264Z",
          "iopub.status.idle": "2024-12-28T13:47:41.557861Z",
          "shell.execute_reply.started": "2024-12-28T13:40:38.203237Z",
          "shell.execute_reply": "2024-12-28T13:47:41.557159Z"
        },
        "id": "m4LBKk7Chp9C"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T13:47:57.3216Z",
          "iopub.execute_input": "2024-12-28T13:47:57.321905Z",
          "iopub.status.idle": "2024-12-28T13:47:57.332514Z",
          "shell.execute_reply.started": "2024-12-28T13:47:57.321882Z",
          "shell.execute_reply": "2024-12-28T13:47:57.331719Z"
        },
        "id": "qZbCCFBvhp9C",
        "outputId": "166c25df-cb31-4805-f60d-d502c24d3d68"
      },
      "outputs": [
        {
          "execution_count": 23,
          "output_type": "execute_result",
          "data": {
            "text/plain": "     index                                           question ground_truth  \\\n0        1  You have successfully logged on a Linux system...            A   \n1        2  What is the following command used for?\\r\\nsql...            B   \n2        3  Sam, a web developer, was instructed to incorp...            D   \n3        4  Which of the following is assured by the use o...            D   \n4        5  What is not a PCI compliance recommendation?\\r...            C   \n..     ...                                                ...          ...   \n145    146  A DDOS attack is performed at layer 7 to take ...            B   \n146    147  A post-breach forensic investigation revealed ...            D   \n147    148  Mirai malware targets loT devices. After infil...            C   \n148    149  Thomas, a cloud security professional, is perf...            C   \n149    150  Tony wants to integrate a 128-bit symmetric bl...            D   \n\n                                                answer  \n0     A. The /var/log/ directory is a standard dire...  \n1     A.  This command is used to enumerate the dat...  \n2     A. Sam is using PGP, which is an open-source ...  \n3                                                    A  \n4     C. All of the above are PCI compliance recomm...  \n..                                                 ...  \n145   C. A session splicing attack is an attempt to...  \n146   D. The patch management process was not follo...  \n147   A. Mirai uses a vulnerability in the open sou...  \n148   D.  The metadata spoofing attack is the most ...  \n149   A. TEA includes all the features required to ...  \n\n[150 rows x 4 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>question</th>\n      <th>ground_truth</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>You have successfully logged on a Linux system...</td>\n      <td>A</td>\n      <td>A. The /var/log/ directory is a standard dire...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>What is the following command used for?\\r\\nsql...</td>\n      <td>B</td>\n      <td>A.  This command is used to enumerate the dat...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Sam, a web developer, was instructed to incorp...</td>\n      <td>D</td>\n      <td>A. Sam is using PGP, which is an open-source ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Which of the following is assured by the use o...</td>\n      <td>D</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>What is not a PCI compliance recommendation?\\r...</td>\n      <td>C</td>\n      <td>C. All of the above are PCI compliance recomm...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>146</td>\n      <td>A DDOS attack is performed at layer 7 to take ...</td>\n      <td>B</td>\n      <td>C. A session splicing attack is an attempt to...</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>147</td>\n      <td>A post-breach forensic investigation revealed ...</td>\n      <td>D</td>\n      <td>D. The patch management process was not follo...</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>148</td>\n      <td>Mirai malware targets loT devices. After infil...</td>\n      <td>C</td>\n      <td>A. Mirai uses a vulnerability in the open sou...</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>149</td>\n      <td>Thomas, a cloud security professional, is perf...</td>\n      <td>C</td>\n      <td>D.  The metadata spoofing attack is the most ...</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>150</td>\n      <td>Tony wants to integrate a 128-bit symmetric bl...</td>\n      <td>D</td>\n      <td>A. TEA includes all the features required to ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>150 rows × 4 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Đánh giá độ tương đồng của câu trả lời với 'ground_truth'"
      ],
      "metadata": {
        "id": "hwuZ3K8ghp9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for i in range(len(test_dataset)):\n",
        "  if (test_dataset['ground_truth'][i] == test_dataset['answer'][i][1]):\n",
        "    count += 1\n",
        "\n",
        "print(count)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T13:48:02.710984Z",
          "iopub.execute_input": "2024-12-28T13:48:02.711275Z",
          "iopub.status.idle": "2024-12-28T13:48:02.717258Z",
          "shell.execute_reply.started": "2024-12-28T13:48:02.711253Z",
          "shell.execute_reply": "2024-12-28T13:48:02.716291Z"
        },
        "id": "qQp47KXghp9D",
        "outputId": "538e3756-f8e9-48ec-ef3c-ae0eeeffb630"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "54\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mô hình dự đoán đúng 54/150 câu, xác suất xấp xỉ 35%"
      ],
      "metadata": {
        "id": "a0Tfj2ikhp9D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the meta-llama"
      ],
      "metadata": {
        "id": "QSqZhYIIhp9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = pd.read_csv('/kaggle/input/b1-dataset-csv/processed_1.csv')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T10:09:38.247335Z",
          "iopub.execute_input": "2024-12-28T10:09:38.247714Z",
          "iopub.status.idle": "2024-12-28T10:09:38.255965Z",
          "shell.execute_reply.started": "2024-12-28T10:09:38.247653Z",
          "shell.execute_reply": "2024-12-28T10:09:38.254976Z"
        },
        "id": "_7MPFTw9hp9E"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T10:09:42.70728Z",
          "iopub.execute_input": "2024-12-28T10:09:42.707578Z",
          "iopub.status.idle": "2024-12-28T10:09:42.717215Z",
          "shell.execute_reply.started": "2024-12-28T10:09:42.707555Z",
          "shell.execute_reply": "2024-12-28T10:09:42.716345Z"
        },
        "id": "poUGIS9php9F",
        "outputId": "426852e5-b3eb-4aac-d1cd-35792bf86186"
      },
      "outputs": [
        {
          "execution_count": 33,
          "output_type": "execute_result",
          "data": {
            "text/plain": "     index                                           question ground_truth\n0        1  You have successfully logged on a Linux system...            A\n1        2  What is the following command used for?\\r\\nsql...            B\n2        3  Sam, a web developer, was instructed to incorp...            D\n3        4  Which of the following is assured by the use o...            D\n4        5  What is not a PCI compliance recommendation?\\r...            C\n..     ...                                                ...          ...\n145    146  A DDOS attack is performed at layer 7 to take ...            B\n146    147  A post-breach forensic investigation revealed ...            D\n147    148  Mirai malware targets loT devices. After infil...            C\n148    149  Thomas, a cloud security professional, is perf...            C\n149    150  Tony wants to integrate a 128-bit symmetric bl...            D\n\n[150 rows x 3 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>question</th>\n      <th>ground_truth</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>You have successfully logged on a Linux system...</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>What is the following command used for?\\r\\nsql...</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Sam, a web developer, was instructed to incorp...</td>\n      <td>D</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Which of the following is assured by the use o...</td>\n      <td>D</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>What is not a PCI compliance recommendation?\\r...</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>146</td>\n      <td>A DDOS attack is performed at layer 7 to take ...</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>147</td>\n      <td>A post-breach forensic investigation revealed ...</td>\n      <td>D</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>148</td>\n      <td>Mirai malware targets loT devices. After infil...</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>149</td>\n      <td>Thomas, a cloud security professional, is perf...</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>150</td>\n      <td>Tony wants to integrate a 128-bit symmetric bl...</td>\n      <td>D</td>\n    </tr>\n  </tbody>\n</table>\n<p>150 rows × 3 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_llama = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B\")\n",
        "model_llama = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-1B\")\n",
        "\n",
        "pipe = pipeline(task='text-generation',\n",
        "                model=model_llama,\n",
        "                tokenizer=tokenizer_llama,\n",
        "                max_new_tokens=250)\n",
        "\n",
        "for i in range(len(test_dataset)):\n",
        "  prompt = 'You are an expert in cybersecurity. Choose the correct answer and give a succinct explanation' + test_dataset['question'][i]\n",
        "  result = pipe(prompt)\n",
        "\n",
        "  test_dataset.loc[i, 'answer'] = result[0]['generated_text']"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T10:27:23.416376Z",
          "iopub.execute_input": "2024-12-28T10:27:23.416727Z",
          "iopub.status.idle": "2024-12-28T10:29:02.555918Z",
          "shell.execute_reply.started": "2024-12-28T10:27:23.416699Z",
          "shell.execute_reply": "2024-12-28T10:29:02.55513Z"
        },
        "id": "e8uVkSsmhp9F"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for i in range(len(test_dataset)):\n",
        "  if (test_dataset['ground_truth'][i] == test_dataset['answer'][i][1]):\n",
        "    count += 1\n",
        "\n",
        "print(count)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T10:30:01.077704Z",
          "iopub.execute_input": "2024-12-28T10:30:01.07805Z",
          "iopub.status.idle": "2024-12-28T10:30:01.084481Z",
          "shell.execute_reply.started": "2024-12-28T10:30:01.078023Z",
          "shell.execute_reply": "2024-12-28T10:30:01.083637Z"
        },
        "id": "jkYZ9E4Uhp9F",
        "outputId": "dbf6bfb0-a9dc-4ffe-d640-41cd4d0bbae6"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "0\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mô hình khi chưa được finetune không trả về format được yêu cầu, dù đã được thử nhiều câu prompts để cố giúp mô hình trả lời theo định dạng -Choice-Reasoning."
      ],
      "metadata": {
        "id": "6tPD3qylhp9G"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "_CRb74x2hp9G"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}